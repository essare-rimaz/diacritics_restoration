{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### BIGRAM LANGUAGE MODEL FOR DIACRITICS RESTORATION #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPROCESSING PRO DICTIONARY ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#otevřít textový soubor - mode \"r\" i.e. read, uložit do proměnné data veškerý text\n",
    "with open(\"corpus_diacritics.txt\", \"r\") as file:\n",
    "    data_split = file.read().split() #split by měl rozdělit na slova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rozdělená slova hodit do lower case\n",
    "data_words_lowered = list(map(lambda x: x.lower(), data_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zbavit se interpunkcí ve strings\n",
    "import re\n",
    "data_no_interpunction = list(map(lambda x: re.sub(r'[^\\w\\s]', '', x) , data_words_lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_no_interpunction[109272:] #odstanění anglické části na konci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_no_interpunction[0:127] #odstanění anglické části na začátku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_interpunction = sorted(data_no_interpunction)\n",
    "del data_no_interpunction[0:579]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = data_no_interpunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DICTIONARY KNOWN WORDS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "data_list_dia = list(OrderedDict.fromkeys(data_ready))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odstranDiakritiku(lst):\n",
    "    upravenySeznam = []\n",
    "    seznamPismenek = \\\n",
    "        [[\"ě\", \"e\"], \\\n",
    "        [\"š\", \"s\"], \\\n",
    "        [\"č\", \"c\"], \\\n",
    "        [\"ř\", \"r\"], \\\n",
    "        [\"ž\", \"z\"], \\\n",
    "        [\"ý\", \"y\"], \\\n",
    "        [\"á\", \"a\"], \\\n",
    "        [\"é\", \"e\"], \\\n",
    "        [\"ň\", \"n\"], \\\n",
    "        [\"ó\", \"o\"], \\\n",
    "        [\"ů\", \"u\"], \\\n",
    "        [\"ú\", \"u\"], \\\n",
    "        [\"ď\", \"d\"], \\\n",
    "        [\"ť\", \"t\"], \\\n",
    "        [\"í\", \"i\"]]\n",
    "    for slovo in lst:\n",
    "        for k in range(len(seznamPismenek)):\n",
    "            slovo = slovo.replace(seznamPismenek[k][0],seznamPismenek[k][1])\n",
    "        upravenySeznam.append(slovo)\n",
    "    return upravenySeznam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#odstraneni diakritiky\n",
    "lst = data_list_dia\n",
    "data_list_no_dia = odstranDiakritiku(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "data_dict_count_dia = Counter(data_ready)\n",
    "\n",
    "data_list_count_dia =[]\n",
    "for key in data_dict_count_dia.keys():\n",
    "    data_list_count_dia.append(data_dict_count_dia[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_data = pd.DataFrame([data_list_no_dia, data_list_dia, data_list_count_dia])#, index=[\"no_dia\", \"dia\", \"count_dia\"])\n",
    "\n",
    "df_data_transposed = df_data.transpose()\n",
    "df_data_transposed = df_data_transposed.rename(columns={0: \"no_dia\", 1: \"dia\", 2: \"count_dia\"})\n",
    "\n",
    "df = df_data_transposed.astype({\"no_dia\": object, \"dia\": object, \"count_dia\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pyenv/versions/3.7.8/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dictionary_words = df[df['count_dia'] == df.groupby('no_dia')['count_dia'].transform('max')].drop(\"count_dia\",axis=1).set_index(\"no_dia\").transpose().to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JAZYKOVY MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus_diacritics.txt\", \"r\") as file:\n",
    "    content = file.read().split()\n",
    "#content = [\" {}\".format(elem) for elem in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rozdělená slova hodit do lower case\n",
    "data_words_lowered = list(map(lambda x: x.lower(), content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zbavit se interpunkcí ve strings\n",
    "import re\n",
    "data_no_interpunction = list(map(lambda x: re.sub(r'[^\\w\\s]', '', x) , data_words_lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_no_interpunction[109272:] #odstanění anglické části na konci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_no_interpunction[0:127] #odstanění anglické části na začátku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkce na vytahovani z elemtu v listu jeden string mimo list\n",
    "def extractChars(lst):\n",
    "    return [list(el) for el in lst]\n",
    "                  \n",
    "lst = data_no_interpunction\n",
    "data_format = extractChars(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nastaveni padding na mezeru misto <s> </s>\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "from nltk.util import everygrams, pad_sequence\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "pad_both_ends = partial(\n",
    "    pad_sequence,\n",
    "    pad_left=True,\n",
    "    left_pad_symbol=\" \",\n",
    "    pad_right=True,\n",
    "    right_pad_symbol=\" \",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(2, data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "lm = MLE(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT PROCESSING PRO HLEDANI V DICT A OUTPUT GENEROVANI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zpravování inputu do správného codingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "fileObj = codecs.open(\"development_set.txt\", \"r\", \"utf-8\" )\n",
    "input_data = fileObj.read() # Returns a Unicode string from the UTF-8 bytes in the file\n",
    "import ftfy\n",
    "input_data = ftfy.fix_text(input_data).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rozdělená slova hodit do lower case\n",
    "input_data_words_lowered = list(map(lambda x: x.lower(), input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zbavit se interpunkcí ve strings\n",
    "import re\n",
    "input_data_no_interpunction = list(map(lambda x: re.sub(r'[^\\w\\s]', '', x) , input_data_words_lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = input_data_no_interpunction\n",
    "input_data_no_dia = odstranDiakritiku(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HLAVNI CAST - OUTPUT GENEROVANI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridejDiakritiku(lst):\n",
    "    upravenySeznam = []\n",
    "    seznamPismenek = \\\n",
    "        [[\"ě\", \"e\"], \\\n",
    "        [\"š\", \"s\"], \\\n",
    "        [\"č\", \"c\"], \\\n",
    "        [\"ř\", \"r\"], \\\n",
    "        [\"ž\", \"z\"], \\\n",
    "        [\"ý\", \"y\"], \\\n",
    "        [\"á\", \"a\"], \\\n",
    "        [\"é\", \"e\"], \\\n",
    "        [\"ň\", \"n\"], \\\n",
    "        [\"ó\", \"o\"], \\\n",
    "        [\"ů\", \"u\"], \\\n",
    "        [\"ú\", \"u\"], \\\n",
    "        [\"ď\", \"d\"], \\\n",
    "        [\"ť\", \"t\"], \\\n",
    "        [\"í\", \"i\"]]\n",
    "    for slovo in lst:\n",
    "        for k in range(len(seznamPismenek)):\n",
    "            slovo = slovo.replace(seznamPismenek[k][1],seznamPismenek[k][0])\n",
    "        upravenySeznam.append(slovo)\n",
    "    return upravenySeznam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seznamPismenek = \\\n",
    "                [[\"ě\", \"e\"], \\\n",
    "                [\"š\", \"s\"], \\\n",
    "                [\"č\", \"c\"], \\\n",
    "                [\"ř\", \"r\"], \\\n",
    "                [\"ž\", \"z\"], \\\n",
    "                [\"ý\", \"y\"], \\\n",
    "                [\"á\", \"a\"], \\\n",
    "                [\"é\", \"e\"], \\\n",
    "                [\"ň\", \"n\"], \\\n",
    "                [\"ó\", \"o\"], \\\n",
    "                [\"ů\", \"u\"], \\\n",
    "                [\"ú\", \"u\"], \\\n",
    "                [\"ď\", \"d\"], \\\n",
    "                [\"ť\", \"t\"], \\\n",
    "                [\"í\", \"i\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringPismenka = \"aeiyoutdszcnr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams\n",
    "output = []\n",
    "rekonstrukce_slova = []\n",
    "#pro vsechna slova v inputu\n",
    "\n",
    "for slovo in input_data_no_dia:\n",
    "    #chci vedet jestli to slovo uz znam a mam v dictu\n",
    "    if slovo in dictionary_words:\n",
    "        #pokud ano tak najdu ekvivalent v dictu a jeho value davam rovnou do outputu\n",
    "        output.append(dictionary_words[slovo])\n",
    "    else:\n",
    "        #zpracovavam input slova abych mohl hledat bigrams\n",
    "        rekonstrukce_slova = []\n",
    "        lst = slovo\n",
    "        data_format = extractChars(lst)        \n",
    "        bigram_format = list(bigrams(pad_both_ends(data_format, n=2)))\n",
    "        \n",
    "        # rozkladam na jednotlive bigramy\n",
    "        for bigram_tupple in bigram_format:\n",
    "\n",
    "            #vytvarim chars aktualniho bigramu abych mohl hledat v jazykovem modelu\n",
    "            bigram_letter_first = bigram_tupple[0]\n",
    "            bigram_letter_second = bigram_tupple[1]\n",
    "            #osetreni toho, ze jsem musel konvertovat na obyceny string\n",
    "            if bigram_letter_first == \" \":\n",
    "                bigram_letter_first = bigram_letter_first\n",
    "            else:\n",
    "                bigram_letter_first = bigram_letter_first[0]\n",
    "            \n",
    "            if bigram_letter_second == \" \":\n",
    "                break #pokud je druhy letter mezera, tak jsem na konci slova\n",
    "            else:\n",
    "                bigram_letter_second = bigram_letter_second[0]\n",
    "            #restoration of diacritics chci delat jenom pro bigramy kde druhe pismeno je v seznamu pismen co maji verzi s diakritikou\n",
    "            if bigram_letter_second in stringPismenka:\n",
    "                #kdyz ma pismeno ze seznamu, tak chci vedet jestli takovy bigram existuje v seznamu bigramu jazykoveho modelu\n",
    "                if lm.score(bigram_letter_second, [bigram_letter_first]) > 0.0:\n",
    "                    #kdyz takovy bigram znam, tak musim vytvorit komplementarni verzi bigramu s diakritikou\n",
    "                    bigram_complement_letter_second = pridejDiakritiku(bigram_letter_second)\n",
    "                    #potrebuju zjistit jestli takovy komplementarni bigram existuje v seznamu bigramu meho jazykoveho modelu\n",
    "                    if lm.score(bigram_complement_letter_second, [bigram_letter_first]) > 0.0:\n",
    "                        #kdyz existuje, pak existuji obe a ja si chci vybrat ten s vetsim score tj. pravdepodobnosti\n",
    "                        if lm.score(bigram_letter_second, [bigram_letter_first])>lm.score(bigram_complement_letter_second, [bigram_letter_first]):\n",
    "                            #pridavam druhe pismeno z bigram bez dia do rekonstrukted\n",
    "                            rekonstrukce_slova.append(bigram_letter_second[0])\n",
    "                        else:\n",
    "                            #pridavam druhe pismeno z bigram s dia do rekonstrukted\n",
    "\n",
    "                            rekonstrukce_slova.append(bigram_complement_letter_second[0])\n",
    "                    else:\n",
    "                        #nemam komplementarni bigram v seznamu, takze vybiram bez diakritiky do rekonstrukted\n",
    "                        rekonstrukce_slova.append(bigram_letter_second[0])\n",
    "                    \n",
    "                else:\n",
    "                    #nemame tento bigram v seznamu jazykoveho modelu\n",
    "                    rekonstrukce_slova.append(bigram_letter_second[0])\n",
    "                    #pridavam druhe pismeno do rekonstrukted\n",
    "            else:\n",
    "                #nema bigram pismeno ze seznamu, druhe pismeno davam do rekonstrukted\n",
    "                rekonstrukce_slova.append(bigram_letter_second[0])\n",
    "                \n",
    "        output.append(\"\".join(rekonstrukce_slova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUACE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#musim vzit vsechno z outputu a jedno podruhym srovnat s inputem ktery ma diakritiku -> pokud se bude rovnat, tak dat na merak +1, pak udelat procento z uspechu a celku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.28477402369461"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i, j in zip(output, input_data_no_interpunction) if i == j])/len(input_data_no_interpunction)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8",
   "language": "python",
   "name": "python-3.7.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
